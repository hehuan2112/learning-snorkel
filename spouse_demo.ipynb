{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting spouse mentions in sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "In this tutorial, we will see how Snorkel can be used for Information Extraction. We will walk through an example text classification task for information extraction, where we use labeling functions involving keywords and distant supervision.\n",
    "\n",
    "* Classification Task *\n",
    "<img src=\"imgs/sentence.jpg\" width=\"700px;\" onerror=\"this.onerror=null; this.src='/doks-theme/assets/images/sentence.jpg';\" align=\"center\" style=\"display: block; margin-left: auto; margin-right: auto;\">\n",
    "\n",
    "We want to classify each __candidate__ or pair of people mentioned in a sentence, as being married at some point or not.\n",
    "\n",
    "In the above example, our candidate represents the possible relation `(Barack Obama, Michelle Obama)`. As readers, we know this mention is true due to external knowledge and the keyword of `wedding` occuring later in the sentence.\n",
    "We begin with some basic setup and data downloading.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "md-exclude"
    ]
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_data\n",
    "\n",
    "((df_dev, Y_dev), df_train, (df_test, Y_test)) = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input Data:** `df_dev`, `df_train`, and `df_test` are `Pandas DataFrame` objects, where each row represents a particular __candidate__. For our problem, a candidate consists of a sentence, and two people mentioned in the sentence. The DataFrames contain the fields `sentence`, which refers to the sentence of the candidate, `tokens`, the tokenized form of the sentence, and `person1_word_idx` and `person2_word_idx`, which represent `[start, end]` indices in the tokens at which the first and second person's name appear, respectively.\n",
    "\n",
    "We also have certain **preprocessed fields**, that we discuss a few cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "md-exclude"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person1_word_idx</th>\n",
       "      <th>person2_word_idx</th>\n",
       "      <th>sentence</th>\n",
       "      <th>tokens</th>\n",
       "      <th>person1_right_tokens</th>\n",
       "      <th>person2_right_tokens</th>\n",
       "      <th>between_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(22, 24)</td>\n",
       "      <td>The Richards are half-sisters to Kathy Hilton, the mother of socialite Paris Hilton and spouse of luxury hotel magnate Richard Howard Hilton.</td>\n",
       "      <td>[The, Richards, are, half, -, sisters, to, Kathy, Hilton, ,, the, mother, of, socialite, Paris, Hilton, and, spouse, of, luxury, hotel, magnate, Richard, Howard, Hilton, ., ]</td>\n",
       "      <td>[are, half, -, sisters]</td>\n",
       "      <td>[., ]</td>\n",
       "      <td>[are, half, -, sisters, to, Kathy, Hilton, ,, the, mother, of, socialite, Paris, Hilton, and, spouse, of, luxury, hotel, magnate]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(7, 8)</td>\n",
       "      <td>The Richards are half-sisters to Kathy Hilton, the mother of socialite Paris Hilton and spouse of luxury hotel magnate Richard Howard Hilton.</td>\n",
       "      <td>[The, Richards, are, half, -, sisters, to, Kathy, Hilton, ,, the, mother, of, socialite, Paris, Hilton, and, spouse, of, luxury, hotel, magnate, Richard, Howard, Hilton, ., ]</td>\n",
       "      <td>[are, half, -, sisters]</td>\n",
       "      <td>[,, the, mother, of]</td>\n",
       "      <td>[are, half, -, sisters, to]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(7, 8)</td>\n",
       "      <td>(22, 24)</td>\n",
       "      <td>The Richards are half-sisters to Kathy Hilton, the mother of socialite Paris Hilton and spouse of luxury hotel magnate Richard Howard Hilton.</td>\n",
       "      <td>[The, Richards, are, half, -, sisters, to, Kathy, Hilton, ,, the, mother, of, socialite, Paris, Hilton, and, spouse, of, luxury, hotel, magnate, Richard, Howard, Hilton, ., ]</td>\n",
       "      <td>[,, the, mother, of]</td>\n",
       "      <td>[., ]</td>\n",
       "      <td>[,, the, mother, of, socialite, Paris, Hilton, and, spouse, of, luxury, hotel, magnate]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(6, 6)</td>\n",
       "      <td>(20, 21)</td>\n",
       "      <td>Prior to both his guests, Colbert's monologue - parts of which he did sitting down - ripped into Donald Trump and his oft-mocked policy of building a wall at the US-Mexico border and not eating Oreos anymore.</td>\n",
       "      <td>[Prior, to, both, his, guests, ,, Colbert, s, monologue, -, parts, of, which, he, did, sitting, down, -, ripped, into, Donald, Trump, and, his, oft, -, mocked, policy, of, building, a, wall, at, the, US, -, Mexico, border, and, not, eating, Oreos, anymore, ., ]</td>\n",
       "      <td>[s, monologue, -, parts]</td>\n",
       "      <td>[and, his, oft, -]</td>\n",
       "      <td>[s, monologue, -, parts, of, which, he, did, sitting, down, -, ripped, into]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>(4, 5)</td>\n",
       "      <td>People reported Williams and Ven Veen tied the knot Saturday at Brush Creek Ranch in Saratoga, Wyoming, in front of about 200 guests.</td>\n",
       "      <td>[People, reported, Williams, and, Ven, Veen, tied, the, knot, Saturday, at, Brush, Creek, Ranch, in, Saratoga, ,, Wyoming, ,, in, front, of, about, 200, guests, .]</td>\n",
       "      <td>[and, Ven, Veen, tied]</td>\n",
       "      <td>[tied, the, knot, Saturday]</td>\n",
       "      <td>[and]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  person1_word_idx person2_word_idx  \\\n",
       "0  (1, 1)           (22, 24)          \n",
       "1  (1, 1)           (7, 8)            \n",
       "2  (7, 8)           (22, 24)          \n",
       "3  (6, 6)           (20, 21)          \n",
       "4  (2, 2)           (4, 5)            \n",
       "\n",
       "                                                                                                                                                                                                                         sentence  \\\n",
       "0  The Richards are half-sisters to Kathy Hilton, the mother of socialite Paris Hilton and spouse of luxury hotel magnate Richard Howard Hilton.                                                                                    \n",
       "1  The Richards are half-sisters to Kathy Hilton, the mother of socialite Paris Hilton and spouse of luxury hotel magnate Richard Howard Hilton.                                                                                    \n",
       "2  The Richards are half-sisters to Kathy Hilton, the mother of socialite Paris Hilton and spouse of luxury hotel magnate Richard Howard Hilton.                                                                                    \n",
       "3  Prior to both his guests, Colbert's monologue - parts of which he did sitting down - ripped into Donald Trump and his oft-mocked policy of building a wall at the US-Mexico border and not eating Oreos anymore.                 \n",
       "4  People reported Williams and Ven Veen tied the knot Saturday at Brush Creek Ranch in Saratoga, Wyoming, in front of about 200 guests.                                                                                            \n",
       "\n",
       "                                                                                                                                                                                                                                                                  tokens  \\\n",
       "0  [The, Richards, are, half, -, sisters, to, Kathy, Hilton, ,, the, mother, of, socialite, Paris, Hilton, and, spouse, of, luxury, hotel, magnate, Richard, Howard, Hilton, ., ]                                                                                          \n",
       "1  [The, Richards, are, half, -, sisters, to, Kathy, Hilton, ,, the, mother, of, socialite, Paris, Hilton, and, spouse, of, luxury, hotel, magnate, Richard, Howard, Hilton, ., ]                                                                                          \n",
       "2  [The, Richards, are, half, -, sisters, to, Kathy, Hilton, ,, the, mother, of, socialite, Paris, Hilton, and, spouse, of, luxury, hotel, magnate, Richard, Howard, Hilton, ., ]                                                                                          \n",
       "3  [Prior, to, both, his, guests, ,, Colbert, s, monologue, -, parts, of, which, he, did, sitting, down, -, ripped, into, Donald, Trump, and, his, oft, -, mocked, policy, of, building, a, wall, at, the, US, -, Mexico, border, and, not, eating, Oreos, anymore, ., ]   \n",
       "4  [People, reported, Williams, and, Ven, Veen, tied, the, knot, Saturday, at, Brush, Creek, Ranch, in, Saratoga, ,, Wyoming, ,, in, front, of, about, 200, guests, .]                                                                                                     \n",
       "\n",
       "       person1_right_tokens         person2_right_tokens  \\\n",
       "0  [are, half, -, sisters]   [., ]                         \n",
       "1  [are, half, -, sisters]   [,, the, mother, of]          \n",
       "2  [,, the, mother, of]      [., ]                         \n",
       "3  [s, monologue, -, parts]  [and, his, oft, -]            \n",
       "4  [and, Ven, Veen, tied]    [tied, the, knot, Saturday]   \n",
       "\n",
       "                                                                                                                      between_tokens  \n",
       "0  [are, half, -, sisters, to, Kathy, Hilton, ,, the, mother, of, socialite, Paris, Hilton, and, spouse, of, luxury, hotel, magnate]  \n",
       "1  [are, half, -, sisters, to]                                                                                                        \n",
       "2  [,, the, mother, of, socialite, Paris, Hilton, and, spouse, of, luxury, hotel, magnate]                                            \n",
       "3  [s, monologue, -, parts, of, which, he, did, sitting, down, -, ripped, into]                                                       \n",
       "4  [and]                                                                                                                              "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Don't truncate text fields in the display\n",
    "pd.set_option(\"display.max_colwidth\", 0)\n",
    "\n",
    "df_dev.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at a candidate in the development set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence:  The Richards are half-sisters to Kathy Hilton, the mother of socialite Paris Hilton and spouse of luxury hotel magnate Richard Howard Hilton.   \n",
      "Person 1:  Kathy Hilton\n",
      "Person 2:  Richard Howard Hilton\n"
     ]
    }
   ],
   "source": [
    "from preprocessors import get_person_text\n",
    "\n",
    "candidate = df_dev.loc[2]\n",
    "person_names = get_person_text(candidate).person_names\n",
    "\n",
    "print(\"Sentence: \", candidate[\"sentence\"])\n",
    "print(\"Person 1: \", person_names[0])\n",
    "print(\"Person 2: \", person_names[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the Data\n",
    "\n",
    "In a real application, there is a lot of data preparation, parsing, and database loading that needs to be completed before we generate candidates and dive into writing labeling functions. Here we've pre-generated candidates in a pandas DataFrame object per split (train,dev,test)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labeling Function Helpers\n",
    "\n",
    "When writing labeling functions, there are several functions you will use over and over again. In the case of text relation extraction as with this task, common functions include those for fetching text between mentions of the two people in a candidate, examing word windows around person mentions, and so on. We will wrap these functions as `preprocessors`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.preprocess import preprocessor\n",
    "\n",
    "\n",
    "@preprocessor()\n",
    "def get_text_between(cand):\n",
    "    \"\"\"\n",
    "    Returns the text between the two person mentions in the sentence for a candidate\n",
    "    \"\"\"\n",
    "    start = cand.person1_word_idx[1] + 1\n",
    "    end = cand.person2_word_idx[0]\n",
    "    cand.text_between = \" \".join(cand.tokens[start:end])\n",
    "    return cand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Candidate PreProcessors\n",
    "\n",
    "For the purposes of the tutorial, we have three fields (`between_tokens`, `person1_right_tokens`, `person2_right_tokens`) preprocessed in the data, which can be used when creating labeling functions. We also provide the following set of `preprocessor`s for this task in `preprocessors.py`, along with the fields these populate.\n",
    "* `get_person_text(cand)`: `person_names`\n",
    "* `get_person_lastnames(cand)`: `person_lastnames`\n",
    "* `get_left_tokens(cand)`: `person1_left_tokens`, `person2_left_tokens`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessors import get_left_tokens, get_person_last_names\n",
    "\n",
    "POSITIVE = 1\n",
    "NEGATIVE = 0\n",
    "ABSTAIN = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LF: basic tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling import labeling_function\n",
    "\n",
    "# Check for the `spouse` words appearing between the person mentions\n",
    "spouses = {\n",
    "    \"spouse\", \"wife\", \"husband\", \"ex-wife\", \"ex-husband\",\n",
    "    \"tied the knot\", \"tie the knot\", \"wedding\", \"married\",\n",
    "}\n",
    "\n",
    "@labeling_function(resources=dict(spouses=spouses))\n",
    "def lf_husband_wife(x, spouses):\n",
    "    return POSITIVE if len(spouses.intersection(set(x.between_tokens))) > 0 else ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for the `spouse` words appearing to the left of the person mentions\n",
    "@labeling_function(resources=dict(spouses=spouses), pre=[get_left_tokens])\n",
    "def lf_husband_wife_left_window(x, spouses):\n",
    "    if len(set(spouses).intersection(set(x.person1_left_tokens))) > 0:\n",
    "        return POSITIVE\n",
    "    elif len(set(spouses).intersection(set(x.person2_left_tokens))) > 0:\n",
    "        return POSITIVE\n",
    "    else:\n",
    "        return ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for the person mentions having the same last name\n",
    "@labeling_function(pre=[get_person_last_names])\n",
    "def lf_same_last_name(x):\n",
    "    p1_ln, p2_ln = x.person_lastnames\n",
    "\n",
    "    if p1_ln and p2_ln and p1_ln == p2_ln:\n",
    "        return POSITIVE\n",
    "    return ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for the word `married` between person mentions\n",
    "@labeling_function()\n",
    "def lf_married(x):\n",
    "    return POSITIVE if \"married\" in x.between_tokens else ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for words that refer to `family` relationships between and to the left of the person mentions\n",
    "family = {\n",
    "    \"father\",\n",
    "    \"mother\",\n",
    "    \"sister\",\n",
    "    \"sisters\",\n",
    "    \"brother\",\n",
    "    \"brothers\",\n",
    "    \"son\",\n",
    "    \"sons\",\n",
    "    \"daughter\",\n",
    "    \"daughters\",\n",
    "    \"grandfather\",\n",
    "    \"grandfathers\",\n",
    "    \"grandmother\",\n",
    "    \"grandmothers\",\n",
    "    \"uncle\",\n",
    "    \"uncles\",\n",
    "    \"aunt\",\n",
    "    \"aunts\",\n",
    "    \"cousin\",\n",
    "    \"cousins\",\n",
    "    \"relative\",\n",
    "}\n",
    "family = family.union({f + \"-in-law\" for f in family})\n",
    "\n",
    "\n",
    "@labeling_function(resources=dict(family=family))\n",
    "def lf_familial_relationship(x, family):\n",
    "    return NEGATIVE if len(family.intersection(set(x.between_tokens))) > 0 else ABSTAIN\n",
    "\n",
    "\n",
    "@labeling_function(resources=dict(family=family), pre=[get_left_tokens])\n",
    "def lf_family_left_window(x, family):\n",
    "    if len(set(family).intersection(set(x.person1_left_tokens))) > 0:\n",
    "        return NEGATIVE\n",
    "    elif len(set(family).intersection(set(x.person2_left_tokens))) > 0:\n",
    "        return NEGATIVE\n",
    "    else:\n",
    "        return ABSTAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LF: EX other relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for `other` relationship words between person mentions\n",
    "other = {\n",
    "    \"boyfriend\", \"girlfriend\", \"boss\", \"employee\", \"secretary\", \n",
    "    \"co-worker\", \"friend\", \"pal\", \"supervisor\", \"mentor\",\n",
    "}\n",
    "\n",
    "\n",
    "@labeling_function(resources=dict(other=other))\n",
    "def lf_other_relationship(x, other):\n",
    "    return NEGATIVE if len(other.intersection(set(x.between_tokens))) > 0 else ABSTAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LF: Distant Supervisions\n",
    "\n",
    "In addition to using factories that encode pattern matching heuristics, we can also write labeling functions that _distantly supervise_ data points. Here, we'll load in a list of known spouse pairs and check to see if the pair of persons in a candidate matches one of these.\n",
    "\n",
    "[**DBpedia**](http://wiki.dbpedia.org/): Our database of known spouses comes from DBpedia, which is a community-driven resource similar to Wikipedia but for curating structured data. We'll use a preprocessed snapshot as our knowledge base for all labeling function development.\n",
    "\n",
    "We can look at some of the example entries from DBPedia and use them in a simple distant supervision labeling function.\n",
    "\n",
    "Make sure `dbpedia.pkl` is in the `spouse/data` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* loaded dbpedia 6126 records\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Diana Lee Inosanto', 'Ron Balicki'),\n",
       " ('Karen Gillmor', 'Paul Gillmor'),\n",
       " ('Chris Hegedus', 'D. A. Pennebaker'),\n",
       " ('Adam Hieronim Sieniawski', 'Katarzyna Kostka'),\n",
       " ('Kabir Khan', 'Mini Mathur')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"data/dbpedia.pkl\", \"rb\") as f:\n",
    "    known_spouses = pickle.load(f)\n",
    "\n",
    "print(\"* loaded dbpedia %d records\" % (len(known_spouses)))\n",
    "list(known_spouses)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function(resources=dict(known_spouses=known_spouses), pre=[get_person_text])\n",
    "def lf_distant_supervision(x, known_spouses):\n",
    "    p1, p2 = x.person_names\n",
    "    if (p1, p2) in known_spouses or (p2, p1) in known_spouses:\n",
    "        return POSITIVE\n",
    "    else:\n",
    "        return ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessors import last_name\n",
    "\n",
    "# Last name pairs for known spouses\n",
    "last_names = set(\n",
    "    [\n",
    "        (last_name(x), last_name(y))\n",
    "        for x, y in known_spouses\n",
    "        if last_name(x) and last_name(y)\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "@labeling_function(resources=dict(last_names=last_names), pre=[get_person_last_names])\n",
    "def lf_distant_supervision_last_names(x, last_names):\n",
    "    p1_ln, p2_ln = x.person_lastnames\n",
    "\n",
    "    return (\n",
    "        POSITIVE\n",
    "        if (p1_ln != p2_ln)\n",
    "        and ((p1_ln, p2_ln) in last_names or (p2_ln, p1_ln) in last_names)\n",
    "        else ABSTAIN\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Labeling Functions to the Data\n",
    "We create a list of labeling functions and apply them to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling import PandasLFApplier\n",
    "\n",
    "lfs = [\n",
    "    lf_husband_wife,\n",
    "    lf_husband_wife_left_window,\n",
    "    lf_same_last_name,\n",
    "    lf_married,\n",
    "    lf_familial_relationship,\n",
    "    lf_family_left_window,\n",
    "    lf_other_relationship,\n",
    "    lf_distant_supervision,\n",
    "    lf_distant_supervision_last_names,\n",
    "]\n",
    "applier = PandasLFApplier(lfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": [
     "md-exclude-output"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2811/2811 [00:07<00:00, 375.79it/s]\n",
      "100%|██████████| 22254/22254 [00:59<00:00, 372.80it/s]\n"
     ]
    }
   ],
   "source": [
    "from snorkel.labeling import LFAnalysis\n",
    "\n",
    "L_dev = applier.apply(df_dev)\n",
    "# first, get L_train based on raw corpus\n",
    "L_train = applier.apply(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "      <th>Correct</th>\n",
       "      <th>Incorrect</th>\n",
       "      <th>Emp. Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lf_husband_wife</th>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.110637</td>\n",
       "      <td>0.059765</td>\n",
       "      <td>0.025969</td>\n",
       "      <td>113</td>\n",
       "      <td>198</td>\n",
       "      <td>0.363344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_husband_wife_left_window</th>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.036642</td>\n",
       "      <td>0.030238</td>\n",
       "      <td>0.006403</td>\n",
       "      <td>40</td>\n",
       "      <td>63</td>\n",
       "      <td>0.388350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_same_last_name</th>\n",
       "      <td>2</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.040555</td>\n",
       "      <td>0.017432</td>\n",
       "      <td>0.009605</td>\n",
       "      <td>19</td>\n",
       "      <td>95</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_married</th>\n",
       "      <td>3</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.019210</td>\n",
       "      <td>0.019210</td>\n",
       "      <td>0.002490</td>\n",
       "      <td>22</td>\n",
       "      <td>32</td>\n",
       "      <td>0.407407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_familial_relationship</th>\n",
       "      <td>4</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.128068</td>\n",
       "      <td>0.063678</td>\n",
       "      <td>0.030950</td>\n",
       "      <td>344</td>\n",
       "      <td>16</td>\n",
       "      <td>0.955556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_family_left_window</th>\n",
       "      <td>5</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.053718</td>\n",
       "      <td>0.043401</td>\n",
       "      <td>0.011384</td>\n",
       "      <td>148</td>\n",
       "      <td>3</td>\n",
       "      <td>0.980132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_other_relationship</th>\n",
       "      <td>6</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.021345</td>\n",
       "      <td>0.006048</td>\n",
       "      <td>0.004980</td>\n",
       "      <td>54</td>\n",
       "      <td>6</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_distant_supervision</th>\n",
       "      <td>7</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.001067</td>\n",
       "      <td>0.001067</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_distant_supervision_last_names</th>\n",
       "      <td>8</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.001067</td>\n",
       "      <td>0.000711</td>\n",
       "      <td>0.000356</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   j Polarity  Coverage  Overlaps  Conflicts  \\\n",
       "lf_husband_wife                    0  [1]      0.110637  0.059765  0.025969    \n",
       "lf_husband_wife_left_window        1  [1]      0.036642  0.030238  0.006403    \n",
       "lf_same_last_name                  2  [1]      0.040555  0.017432  0.009605    \n",
       "lf_married                         3  [1]      0.019210  0.019210  0.002490    \n",
       "lf_familial_relationship           4  [0]      0.128068  0.063678  0.030950    \n",
       "lf_family_left_window              5  [0]      0.053718  0.043401  0.011384    \n",
       "lf_other_relationship              6  [0]      0.021345  0.006048  0.004980    \n",
       "lf_distant_supervision             7  [1]      0.001067  0.001067  0.000000    \n",
       "lf_distant_supervision_last_names  8  [1]      0.001067  0.000711  0.000356    \n",
       "\n",
       "                                   Correct  Incorrect  Emp. Acc.  \n",
       "lf_husband_wife                    113      198        0.363344   \n",
       "lf_husband_wife_left_window        40       63         0.388350   \n",
       "lf_same_last_name                  19       95         0.166667   \n",
       "lf_married                         22       32         0.407407   \n",
       "lf_familial_relationship           344      16         0.955556   \n",
       "lf_family_left_window              148      3          0.980132   \n",
       "lf_other_relationship              54       6          0.900000   \n",
       "lf_distant_supervision             2        1          0.666667   \n",
       "lf_distant_supervision_last_names  0        3          0.000000   "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LFAnalysis(L_dev, lfs).lf_summary(Y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Label Model\n",
    "\n",
    "Now, we'll train a model of the LFs to estimate their weights and combine their outputs. Once the model is trained, we can combine the outputs of the LFs into a single, noise-aware training label set for our extractor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": [
     "md-exclude-output"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/m210842/opt/miniconda3/envs/nlpy37/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "INFO:root:Computing O...\n",
      "INFO:root:Estimating \\mu...\n",
      "  0%|          | 0/5000 [00:00<?, ?epoch/s]INFO:root:[0 epochs]: TRAIN:[loss=0.008]\n",
      "  9%|▉         | 465/5000 [00:00<00:02, 1610.68epoch/s]INFO:root:[500 epochs]: TRAIN:[loss=0.001]\n",
      " 20%|█▉        | 981/5000 [00:00<00:02, 1684.44epoch/s]INFO:root:[1000 epochs]: TRAIN:[loss=0.001]\n",
      " 27%|██▋       | 1326/5000 [00:00<00:02, 1709.53epoch/s]INFO:root:[1500 epochs]: TRAIN:[loss=0.001]\n",
      " 37%|███▋      | 1854/5000 [00:01<00:01, 1741.60epoch/s]INFO:root:[2000 epochs]: TRAIN:[loss=0.001]\n",
      " 47%|████▋     | 2374/5000 [00:01<00:01, 1684.04epoch/s]INFO:root:[2500 epochs]: TRAIN:[loss=0.001]\n",
      " 58%|█████▊    | 2884/5000 [00:01<00:01, 1688.58epoch/s]INFO:root:[3000 epochs]: TRAIN:[loss=0.001]\n",
      " 68%|██████▊   | 3400/5000 [00:02<00:00, 1653.91epoch/s]INFO:root:[3500 epochs]: TRAIN:[loss=0.001]\n",
      " 78%|███████▊  | 3901/5000 [00:02<00:00, 1634.77epoch/s]INFO:root:[4000 epochs]: TRAIN:[loss=0.001]\n",
      " 88%|████████▊ | 4396/5000 [00:02<00:00, 1611.85epoch/s]INFO:root:[4500 epochs]: TRAIN:[loss=0.001]\n",
      "100%|██████████| 5000/5000 [00:03<00:00, 1659.32epoch/s]\n",
      "INFO:root:Finished Training\n"
     ]
    }
   ],
   "source": [
    "from snorkel.labeling.model import LabelModel\n",
    "\n",
    "label_model = LabelModel(cardinality=2, verbose=True)\n",
    "label_model.fit(L_train, Y_dev, n_epochs=5000, log_freq=500, seed=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Model Metrics\n",
    "Since our dataset is highly unbalanced (91% of the labels are negative), even a trivial baseline that always outputs negative can get a high accuracy. So we evaluate the label model using the F1 score and ROC-AUC rather than accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label model f1 score: 0.4495238095238095\n",
      "Label model roc-auc: 0.7544328199361433\n"
     ]
    }
   ],
   "source": [
    "from snorkel.analysis import metric_score\n",
    "from snorkel.utils import probs_to_preds\n",
    "\n",
    "probs_dev = label_model.predict_proba(L_dev)\n",
    "preds_dev = probs_to_preds(probs_dev)\n",
    "print(\n",
    "    f\"Label model f1 score: {metric_score(Y_dev, preds_dev, probs=probs_dev, metric='f1')}\"\n",
    ")\n",
    "print(\n",
    "    f\"Label model roc-auc: {metric_score(Y_dev, preds_dev, probs=probs_dev, metric='roc_auc')}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Analysis of errors \n",
    "\n",
    "In fact, it's better to know why there are so many errors to improve the rules.\n",
    "After analyzing the errors, you can improve the rule or add new rules to capture more cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Tuple\n",
    "\n",
    "def filter_labeled_dataframe(\n",
    "    X: pd.DataFrame, Y: np.ndarray, P: np.ndarray, L: np.ndarray\n",
    "):\n",
    "    \"\"\"Filter out examples covered by any labeling function.\n",
    "    Parameters\n",
    "    ----------\n",
    "    X\n",
    "        Data points in a Pandas DataFrame.\n",
    "    Y\n",
    "        Data points of ground truth.\n",
    "    P\n",
    "        Matrix of probabilities output by label model's predict_proba method.\n",
    "    L\n",
    "        Matrix of labels emitted by LFs.\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Data points that were labeled by at least one LF in L.\n",
    "    np.ndarray\n",
    "        Probabilities matrix for data points labeled by at least one LF in L.\n",
    "    \"\"\"\n",
    "    mask = (L == -1).all(axis=1)\n",
    "    return X.iloc[mask], Y[mask], P[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* got 2050 error records in dev\n"
     ]
    }
   ],
   "source": [
    "probs_dev = label_model.predict_proba(L_dev)\n",
    "df_errors, y_errors, p_errors = filter_labeled_dataframe(df_dev, Y_dev, probs_dev, L_dev)\n",
    "\n",
    "print('* got %d error records in dev' % (len(df_errors)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "* (1) [Williams]-[Ven Veen]: People reported <span style='color:red'>Williams</span> and <span style='color:green'>Ven Veen</span> tied the knot Saturday at Brush Creek Ranch in Saratoga, Wyoming, in front of about 200 guests."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "* (1) [Faith Jenkinson]-[Andrew Asher]: Michael Ulatowski (pictured) did not finalise the divorce with his wife <span style='color:red'>Faith Jenkinson</span>, but she went to marry another man,  <span style='color:green'>Andrew Asher</span>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "* (1) [Mr Asher]-[Jenkinson]: <span style='color:red'>Mr Asher</span>, who described the sham marriage as 'good for two and half years,' has now separated from <span style='color:green'>Jenkinson</span> and the wedding was declared void by Lincoln Family Court on 12 June 2014, the court was told.    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "* (1) [Thomas]-[Caren Teves]: <span style='color:red'>Thomas</span> and <span style='color:green'>Caren Teves</span> (AZ), whose 24 year-old Alex Teves was killed in the Aurora movie theater shooting in July 2012 ."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "* (1) [Kelli]-[Ewen]: His heartbroken wife <span style='color:red'>Kelli</span> (pictured with <span style='color:green'>Ewen</span>) said she had lost the 'love of her life' after the death of the player who had been battling depression     Enforcer <span style='color:green'>Ewen</span> was dubbed 'The Animal' for his tough playing style which won him an impressive 36 goals, 40 assists and 1,911 penalty minutes across 518 games (pictured playing with the Montreal Canadiens against the Boston Bruins in the 1990s, right, and with St. Louis Blues in November of 1988, left)   Blues Chairman Tom Stillman  issued a moving statement on the club's website , saying: 'We are deeply saddened by the passing of former Blue Todd <span style='color:green'>Ewen</span>.   '"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "* (1) [Anita Lesko]-[Abraham Talmage Nielsen]: On Sunday, <span style='color:red'>Anita Lesko</span> and <span style='color:green'>Abraham Talmage Nielsen</span> got married surrounded by 185 of their friends, family and supporters."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "* (1) [Pam]-[John]: And the number of homes being built does not match the growth in our population.’   <span style='color:red'>Pam</span> and <span style='color:green'>John</span> bought their first home, a new three-bedroom terrace house in Hampshire for £8,700 in 1972, before they married, in their mid-20s.   "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "* (1) [Ryan]-[Beau Ryan s]: I'll be totally honest with you - I think it's nobody's business but <span style='color:red'>Ryan</span>'s, Beau <span style='color:red'>Ryan</span>'s (Wife), Lauren Brant and her fiance,' Johns said.    'We don't need to hear from Beau <span style='color:red'>Ryan</span>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "* (1) [Ryan]-[Lauren Brant]: I'll be totally honest with you - I think it's nobody's business but <span style='color:red'>Ryan</span>'s, Beau <span style='color:red'>Ryan</span>'s (Wife), <span style='color:green'>Lauren Brant</span> and her fiance,' Johns said.    'We don't need to hear from Beau <span style='color:red'>Ryan</span>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "cnt = 0\n",
    "for i in range(0, len(df_errors)):\n",
    "    r = df_errors.iloc[i]\n",
    "    y = y_errors[i]\n",
    "    if y == 0: continue\n",
    "    \n",
    "    cnt += 1\n",
    "    if cnt == 10: break\n",
    "    \n",
    "    names = get_person_text(r).person_names\n",
    "    sent = r['sentence']\n",
    "    sent = sent.replace(names[0], \"<span style='color:red'>%s</span>\" % names[0])\n",
    "    sent = sent.replace(names[1], \"<span style='color:green'>%s</span>\" % names[1])\n",
    "    \n",
    "    display(HTML('* (%s) [%s]-[%s]: %s' % (\n",
    "        y, names[0], names[1], sent\n",
    "    )))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, in the following case:\n",
    "\n",
    "```\n",
    "* (0) [Richards]-[Kathy Hilton]: The Richards are half-sisters to Kathy Hilton, the mother of socialite Paris Hilton and spouse of luxury hotel magnate Richard Howard Hilton.\n",
    "```\n",
    "\n",
    "Existing rules cannot capture the \"half-sisters\" relationship, which results in the deletion of this case in future filtered training set. The will casue the loss in training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "source": [
    "# Part 4: Training our End Extraction Model\n",
    "\n",
    "In this final section of the tutorial, we'll use our noisy training labels to train our end machine learning model. We start by filtering out training data points which did not recieve a label from any LF, as these data points contain no signal.\n",
    "\n",
    "The `L_train` is the output of LModel based on the input.\n",
    "\n",
    "The `probs_train` is the probability of `L_train` labels. So, if the labels are the same, the probs are same as well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Size of df_train: 22254\n",
      "* Size of filtered: 6177\n"
     ]
    }
   ],
   "source": [
    "from snorkel.labeling import filter_unlabeled_dataframe\n",
    "\n",
    "probs_train = label_model.predict_proba(L_train)\n",
    "df_train_filtered, probs_train_filtered = filter_unlabeled_dataframe(\n",
    "    X=df_train, \n",
    "    y=probs_train, \n",
    "    L=L_train\n",
    ")\n",
    "print('* Size of df_train:', len(df_train))\n",
    "print('* Size of filtered:', len(df_train_filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "       [-1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "       [-1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "       [-1,  1, -1, -1, -1, -1, -1, -1, -1],\n",
       "       [ 1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "       [ 1,  1, -1, -1, -1, -1, -1, -1, -1]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_train[:6, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9324084 , 0.0675916 ],\n",
       "       [0.9324084 , 0.0675916 ],\n",
       "       [0.9324084 , 0.0675916 ],\n",
       "       [0.29667719, 0.70332281],\n",
       "       [0.42529014, 0.57470986],\n",
       "       [0.02212763, 0.97787237]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs_train[:6, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we train a simple [LSTM](https://en.wikipedia.org/wiki/Long_short-term_memory) network for classifying candidates. `tf_model` contains functions for processing features and building the keras model for training and evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try with TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tf_model import get_feature_arrays\n",
    "from utils import get_n_epochs\n",
    "\n",
    "from tensorflow.keras.layers import (\n",
    "    Bidirectional,\n",
    "    Concatenate,\n",
    "    Dense,\n",
    "    Embedding,\n",
    "    Input,\n",
    "    LSTM,\n",
    ")\n",
    "\n",
    "def bilstm(\n",
    "    tokens: tf.Tensor,\n",
    "    rnn_state_size: int = 64,\n",
    "    num_buckets: int = 40000,\n",
    "    embed_dim: int = 36,\n",
    "):\n",
    "    ids = tf.strings.to_hash_bucket(tokens, num_buckets)\n",
    "    embedded_input = Embedding(num_buckets, embed_dim)(ids)\n",
    "    return Bidirectional(LSTM(rnn_state_size, activation=tf.nn.relu))(\n",
    "        embedded_input, mask=tf.strings.length(tokens)\n",
    "    )\n",
    "\n",
    "def get_model(\n",
    "    rnn_state_size: int = 64, \n",
    "    num_buckets: int = 40000, \n",
    "    embed_dim: int = 12,\n",
    "    learning_rate: float = 0.001\n",
    ") -> tf.keras.Model:\n",
    "    \"\"\"\n",
    "    Return LSTM model for predicting label probabilities.\n",
    "    Args:\n",
    "        rnn_state_size: LSTM state size.\n",
    "        num_buckets: Number of buckets to hash strings to integers.\n",
    "        embed_dim: Size of token embeddings.\n",
    "    Returns:\n",
    "        model: A compiled LSTM model.\n",
    "    \"\"\"\n",
    "    left_ph = Input((None,), dtype=\"string\")\n",
    "    bet_ph = Input((None,), dtype=\"string\")\n",
    "    right_ph = Input((None,), dtype=\"string\")\n",
    "    left_embs = bilstm(left_ph, rnn_state_size, num_buckets, embed_dim)\n",
    "    bet_embs = bilstm(bet_ph, rnn_state_size, num_buckets, embed_dim)\n",
    "    right_embs = bilstm(right_ph, rnn_state_size, num_buckets, embed_dim)\n",
    "    layer = Concatenate(1)([left_embs, bet_embs, right_embs])\n",
    "    layer = Dense(64, activation=tf.nn.relu)(layer)\n",
    "    layer = Dense(32, activation=tf.nn.relu)(layer)\n",
    "    probabilities = Dense(2, activation=tf.nn.softmax)(layer)\n",
    "    model = tf.keras.Model(inputs=[bet_ph, left_ph, right_ph], outputs=probabilities)\n",
    "    model.compile(tf.optimizers.Adam(learning_rate), \"categorical_crossentropy\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test with dev df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "44/44 [==============================] - 11s 66ms/step - loss: 0.5132\n",
      "Epoch 2/20\n",
      "44/44 [==============================] - 3s 77ms/step - loss: 0.4190\n",
      "Epoch 3/20\n",
      "44/44 [==============================] - 3s 74ms/step - loss: 0.3834\n",
      "Epoch 4/20\n",
      "44/44 [==============================] - 3s 79ms/step - loss: 0.3486\n",
      "Epoch 5/20\n",
      "44/44 [==============================] - 4s 80ms/step - loss: 0.3220\n",
      "Epoch 6/20\n",
      "44/44 [==============================] - 4s 83ms/step - loss: 0.3122\n",
      "Epoch 7/20\n",
      "44/44 [==============================] - 3s 78ms/step - loss: 0.3071\n",
      "Epoch 8/20\n",
      "44/44 [==============================] - 3s 77ms/step - loss: 0.3039\n",
      "Epoch 9/20\n",
      "44/44 [==============================] - 3s 77ms/step - loss: 0.3019\n",
      "Epoch 10/20\n",
      "44/44 [==============================] - 3s 74ms/step - loss: 0.3011\n",
      "Epoch 11/20\n",
      "44/44 [==============================] - 3s 78ms/step - loss: 0.3008\n",
      "Epoch 12/20\n",
      "44/44 [==============================] - 4s 82ms/step - loss: 0.2999\n",
      "Epoch 13/20\n",
      "44/44 [==============================] - 4s 84ms/step - loss: 0.2997\n",
      "Epoch 14/20\n",
      "44/44 [==============================] - 4s 88ms/step - loss: 0.2993\n",
      "Epoch 15/20\n",
      "44/44 [==============================] - 4s 83ms/step - loss: 0.2991\n",
      "Epoch 16/20\n",
      "44/44 [==============================] - 4s 84ms/step - loss: 0.2988\n",
      "Epoch 17/20\n",
      "44/44 [==============================] - 4s 90ms/step - loss: 0.2986\n",
      "Epoch 18/20\n",
      "44/44 [==============================] - 3s 78ms/step - loss: 0.2985\n",
      "Epoch 19/20\n",
      "44/44 [==============================] - 4s 88ms/step - loss: 0.2985\n",
      "Epoch 20/20\n",
      "44/44 [==============================] - 4s 82ms/step - loss: 0.2985\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9cc133d190>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3 = get_model()\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "\n",
    "X_dev = get_feature_arrays(df_dev)\n",
    "probs_dev = label_model.predict_proba(L_dev)\n",
    "\n",
    "model3.fit(X_dev, probs_dev, batch_size=batch_size, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 2s 9ms/step\n",
      "Test F1 when trained with soft labels: 0.3414634146341463\n",
      "Test ROC-AUC when trained with soft labels: 0.7149626635432869\n"
     ]
    }
   ],
   "source": [
    "X_test = get_feature_arrays(df_test)\n",
    "probs_test3 = model3.predict(X_test)\n",
    "preds_test3 = probs_to_preds(probs_test3)\n",
    "print(\n",
    "    f\"Test F1 when trained with soft labels: {metric_score(Y_test, preds=preds_test3, metric='f1')}\"\n",
    ")\n",
    "print(\n",
    "    f\"Test ROC-AUC when trained with soft labels: {metric_score(Y_test, probs=probs_test3, metric='roc_auc')}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test with filtered df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": [
     "md-exclude-output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "97/97 [==============================] - 14s 63ms/step - loss: 0.6500\n",
      "Epoch 2/10\n",
      "97/97 [==============================] - 7s 70ms/step - loss: 0.5194\n",
      "Epoch 3/10\n",
      "97/97 [==============================] - 7s 76ms/step - loss: 0.4816\n",
      "Epoch 4/10\n",
      "97/97 [==============================] - 9s 89ms/step - loss: 0.4651\n",
      "Epoch 5/10\n",
      "97/97 [==============================] - 10s 105ms/step - loss: 0.4557\n",
      "Epoch 6/10\n",
      "97/97 [==============================] - 8s 79ms/step - loss: 0.4517\n",
      "Epoch 7/10\n",
      "97/97 [==============================] - 7s 76ms/step - loss: 0.4494\n",
      "Epoch 8/10\n",
      "97/97 [==============================] - 7s 72ms/step - loss: 0.4482\n",
      "Epoch 9/10\n",
      "97/97 [==============================] - 7s 72ms/step - loss: 0.4475\n",
      "Epoch 10/10\n",
      "97/97 [==============================] - 7s 71ms/step - loss: 0.4469\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9cb11ec5d0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = get_feature_arrays(df_train_filtered)\n",
    "model = get_model()\n",
    "batch_size = 64\n",
    "model.fit(X_train, probs_train_filtered, batch_size=batch_size, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we evaluate the trained model by measuring its F1 score and ROC_AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 2s 9ms/step\n",
      "Test F1 when trained with soft labels: 0.39143730886850153\n",
      "Test ROC-AUC when trained with soft labels: 0.7650759106880919\n"
     ]
    }
   ],
   "source": [
    "X_test = get_feature_arrays(df_test)\n",
    "probs_test = model.predict(X_test)\n",
    "preds_test = probs_to_preds(probs_test)\n",
    "print(\n",
    "    f\"Test F1 when trained with soft labels: {metric_score(Y_test, preds=preds_test, metric='f1')}\"\n",
    ")\n",
    "print(\n",
    "    f\"Test ROC-AUC when trained with soft labels: {metric_score(Y_test, probs=probs_test, metric='roc_auc')}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test with ALL df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "348/348 [==============================] - 35s 76ms/step - loss: 0.4021\n",
      "Epoch 2/20\n",
      "348/348 [==============================] - 27s 78ms/step - loss: 0.3263\n",
      "Epoch 3/20\n",
      "348/348 [==============================] - 27s 78ms/step - loss: 0.3173\n",
      "Epoch 4/20\n",
      "348/348 [==============================] - 27s 78ms/step - loss: 0.3115\n",
      "Epoch 5/20\n",
      "348/348 [==============================] - 27s 77ms/step - loss: 0.3082\n",
      "Epoch 6/20\n",
      "348/348 [==============================] - 28s 80ms/step - loss: 0.3061\n",
      "Epoch 7/20\n",
      "348/348 [==============================] - 28s 80ms/step - loss: 0.3053\n",
      "Epoch 8/20\n",
      "348/348 [==============================] - 27s 78ms/step - loss: 0.3045\n",
      "Epoch 9/20\n",
      "348/348 [==============================] - 29s 82ms/step - loss: 0.3041\n",
      "Epoch 10/20\n",
      "348/348 [==============================] - 27s 78ms/step - loss: 0.3040\n",
      "Epoch 11/20\n",
      "348/348 [==============================] - 28s 81ms/step - loss: 0.3036\n",
      "Epoch 12/20\n",
      "348/348 [==============================] - 27s 79ms/step - loss: 0.3033\n",
      "Epoch 13/20\n",
      "348/348 [==============================] - 28s 80ms/step - loss: 0.3032\n",
      "Epoch 14/20\n",
      "348/348 [==============================] - 28s 81ms/step - loss: 0.3031\n",
      "Epoch 15/20\n",
      "348/348 [==============================] - 29s 83ms/step - loss: 0.3029\n",
      "Epoch 16/20\n",
      "348/348 [==============================] - 29s 83ms/step - loss: 0.3029\n",
      "Epoch 17/20\n",
      "348/348 [==============================] - 28s 79ms/step - loss: 0.3028\n",
      "Epoch 18/20\n",
      "348/348 [==============================] - 30s 85ms/step - loss: 0.3027\n",
      "Epoch 19/20\n",
      "348/348 [==============================] - 28s 81ms/step - loss: 0.3026\n",
      "Epoch 20/20\n",
      "348/348 [==============================] - 29s 82ms/step - loss: 0.3026\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9ca588f890>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = get_feature_arrays(df_train)\n",
    "model2 = get_model()\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "model2.fit(X_train, probs_train, batch_size=batch_size, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 2s 9ms/step\n",
      "Test F1 when trained with soft labels: 0.4810126582278481\n",
      "Test ROC-AUC when trained with soft labels: 0.7758168389082458\n"
     ]
    }
   ],
   "source": [
    "X_test = get_feature_arrays(df_test)\n",
    "probs_test2 = model2.predict(X_test)\n",
    "preds_test2 = probs_to_preds(probs_test2)\n",
    "print(\n",
    "    f\"Test F1 when trained with soft labels: {metric_score(Y_test, preds=preds_test2, metric='f1')}\"\n",
    ")\n",
    "print(\n",
    "    f\"Test ROC-AUC when trained with soft labels: {metric_score(Y_test, probs=probs_test2, metric='roc_auc')}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "* (79.03% spouse) [Sylvia Plath]-[Ted Hughes]: Fatal attraction: <span style='color:red'>Sylvia Plath</span> met <span style='color:green'>Ted Hughes</span> at Cambridge University and married him only months later    On the Monday he learned that Plath was dead."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "* (5.02% spouse) [Michael Slager]-[Scarlett Wilson]: Circuit Judge Clifton Newman denied bond for <span style='color:red'>Michael Slager</span> on Monday after he made his first court appearance last week The former North Charleston officer has been held in solitary confinement since his arrest on murder charges in the April 4 death of Walter Scott Prosecutor <span style='color:green'>Scarlett Wilson</span> on Thursday called Slager 'a firing squad and executioner' and said he planted evidence   A judge denied bail Monday for a white former South Carolina police officer charged with murder in the shooting death of a black motorist, saying his release would 'constitute an unreasonable danger to the community.'   "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "* (68.62% spouse) [Joe Davis]-[Kim Davis]: <span style='color:red'>Joe Davis</span>, the husband of Rowan County Clerk <span style='color:green'>Kim Davis</span>, said she's in good spirits after spending the night behind bars but insists she will not resign in the midst of the controversy.   "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "* (6.27% spouse) [Cupco]-[Zaza]: In the picture, <span style='color:red'>Cupco</span>'s hair was pulled back into a bun as she kissed <span style='color:green'>Zaza</span>'s nose."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "* (6.10% spouse) [Bro Code]-[Sam]: David's exit was set in motion earlier in the night when he decided to break the <span style='color:red'>Bro Code</span> and interrupt <span style='color:green'>Sam</span>'s one-on-one time with footballer Michael, because he felt threatened by his 'position' and 'tattoos'.      "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_case = df_train.sample(5)\n",
    "X_case = get_feature_arrays(df_case)\n",
    "y_case = model2.predict(X_case)\n",
    "\n",
    "for i in range(0, len(df_case)):\n",
    "    r = df_case.iloc[i]\n",
    "    y = y_case[i][1] * 100\n",
    "    \n",
    "    names = get_person_text(r).person_names\n",
    "    sent = r['sentence']\n",
    "    sent = sent.replace(names[0], \"<span style='color:red'>%s</span>\" % names[0])\n",
    "    sent = sent.replace(names[1], \"<span style='color:green'>%s</span>\" % names[1])\n",
    "    \n",
    "    display(HTML('* (%.2f%% spouse) [%s]-[%s]: %s' % (\n",
    "        y, names[0], names[1], sent\n",
    "    )))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    ">   In this tutorial, we showed how Snorkel can be used for Information Extraction. We demonstrated how to create LFs that leverage keywords and external knowledge bases (distant supervision). Finally, we showed how a model trained using the probabilistic outputs of the Label Model can achieve comparable performance while generalizing to all data points.\n",
    "\n",
    "TLDR\n",
    "1. Small dataset (df_dev) works but low performance\n",
    "2. Filtered generated dataset (filtered df_train) works better and trains quickly\n",
    "3. All generated dataset (all df_train) works best but long time to train and use\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "tags,-all"
  },
  "kernelspec": {
   "display_name": "NLPy37",
   "language": "python",
   "name": "nlpy37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
